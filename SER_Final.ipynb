{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Libraries"
      ],
      "metadata": {
        "id": "-5MEQm-w1KuQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "JAi6ZKv81KFZ",
        "outputId": "c20688eb-742e-4308-9666-82d99babb657"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5bc567c6057f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMyDrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCodeFiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMyDrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCodeFiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "from drive.MyDrive.CodeFiles.SERCode.Code.features1 import *\n",
        "from drive.MyDrive.CodeFiles.SERCode.Code.helper import *\n",
        "\n",
        "!pip install audiosegment\n",
        "!sudo apt-get install libportaudio2\n",
        "!pip install sounddevice\n",
        "!apt-get install -y sox\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import audiosegment\n",
        "import sounddevice as sd\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import wave\n",
        "import copy\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "from scipy import signal\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.layers import LSTM, Input, Flatten, Embedding, Conv1D, Conv2D, Dropout, MaxPooling2D, Bidirectional\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IEMOCAP DATA COLLECTION"
      ],
      "metadata": {
        "id": "8EWmAXpC-fq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "nb_feat = 34\n",
        "nb_class = 4\n",
        "nb_epoch = 80\n",
        "\n",
        "optimizer = 'Adadelta'\n",
        "\n",
        "\n",
        "emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n",
        "data_path = \"/content/drive/MyDrive/Data/\"\n",
        "sessions = ['Session1','Session2','Session3','Session4','Session5']\n",
        "framerate = 16000\n",
        "\n",
        "def get_mocap_rot(path_to_mocap_rot, filename, start,end):\n",
        "    f = open(path_to_mocap_rot + filename, 'r').read()\n",
        "    f = np.array(f.split('\\n'))\n",
        "    mocap_rot = []\n",
        "    mocap_rot_avg = []\n",
        "    f = f[2:]\n",
        "    counter = 0\n",
        "    for data in f:\n",
        "        counter+=1\n",
        "        data2 = data.split(' ')\n",
        "        if(len(data2)<2):\n",
        "            continue\n",
        "        if(float(data2[1])>start and float(data2[1])<end):\n",
        "            mocap_rot_avg.append(np.array(data2[2:]).astype(float))\n",
        "\n",
        "    mocap_rot_avg = np.array_split(np.array(mocap_rot_avg), 200)\n",
        "    for spl in mocap_rot_avg:\n",
        "        mocap_rot.append(np.mean(spl, axis=0))\n",
        "    return np.array(mocap_rot)\n",
        "\n",
        "def get_mocap_hand(path_to_mocap_hand, filename, start,end):\n",
        "    f = open(path_to_mocap_hand + filename, 'r').read()\n",
        "    f = np.array(f.split('\\n'))\n",
        "    mocap_hand = []\n",
        "    mocap_hand_avg = []\n",
        "    f = f[2:]\n",
        "    counter = 0\n",
        "    for data in f:\n",
        "        counter+=1\n",
        "        data2 = data.split(' ')\n",
        "        if(len(data2)<2):\n",
        "            continue\n",
        "        if(float(data2[1])>start and float(data2[1])<end):\n",
        "            mocap_hand_avg.append(np.array(data2[2:]).astype(float))\n",
        "\n",
        "    mocap_hand_avg = np.array_split(np.array(mocap_hand_avg), 200)\n",
        "    for spl in mocap_hand_avg:\n",
        "        mocap_hand.append(np.mean(spl, axis=0))\n",
        "    return np.array(mocap_hand)\n",
        "\n",
        "def get_mocap_head(path_to_mocap_head, filename, start,end):\n",
        "    f = open(path_to_mocap_head + filename, 'r').read()\n",
        "    f = np.array(f.split('\\n'))\n",
        "    mocap_head = []\n",
        "    mocap_head_avg = []\n",
        "    f = f[2:]\n",
        "    counter = 0\n",
        "    for data in f:\n",
        "        counter+=1\n",
        "        data2 = data.split(' ')\n",
        "        if(len(data2)<2):\n",
        "            continue\n",
        "        if(float(data2[1])>start and float(data2[1])<end):\n",
        "            mocap_head_avg.append(np.array(data2[2:]).astype(float))\n",
        "\n",
        "    mocap_head_avg = np.array_split(np.array(mocap_head_avg), 200)\n",
        "    for spl in mocap_head_avg:\n",
        "        mocap_head.append(np.mean(spl, axis=0))\n",
        "    return np.array(mocap_head)\n",
        "\n",
        "\n",
        "\n",
        "def read_iemocap_mocap():\n",
        "    data = []\n",
        "    ids = {}\n",
        "    for session in sessions:\n",
        "        path_to_wav = data_path + session + '/dialog/wav/'\n",
        "        path_to_emotions = data_path +session + '/dialog/EmoEvaluation/'\n",
        "        path_to_transcriptions = data_path  + session + '/dialog/transcriptions/'\n",
        "        path_to_mocap_hand = data_path + session + '/dialog/MOCAP_hand/'\n",
        "        path_to_mocap_rot = data_path + session + '/dialog/MOCAP_rotated/'\n",
        "        path_to_mocap_head = data_path + session + '/dialog/MOCAP_head/'\n",
        "\n",
        "        files2 = os.listdir(path_to_wav)\n",
        "\n",
        "        files = []\n",
        "        for f in files2:\n",
        "            if f.endswith(\".wav\"):\n",
        "                if f[0] == '.':\n",
        "                    files.append(f[2:-4])\n",
        "                else:\n",
        "                    files.append(f[:-4])\n",
        "\n",
        "\n",
        "        for f in files:\n",
        "            print(f)\n",
        "            mocap_f = f\n",
        "            if (f== 'Ses05M_script01_1b'):\n",
        "                mocap_f = 'Ses05M_script01_1'\n",
        "\n",
        "            wav = get_audio(path_to_wav, f + '.wav')\n",
        "            transcriptions = get_transcriptions(path_to_transcriptions , f + '.txt')\n",
        "\n",
        "            emotions = get_emotions(path_to_emotions, f + '.txt')\n",
        "            sample = split_wav(wav, emotions)\n",
        "\n",
        "            for ie, e in enumerate(emotions):\n",
        "                '''if 'F' in e['id']:\n",
        "                    e['signal'] = sample[ie]['left']\n",
        "                else:\n",
        "                    e['signal'] = sample[ie]['right']'''\n",
        "\n",
        "                e['signal'] = sample[ie]['left']\n",
        "                e.pop(\"left\", None)\n",
        "                e.pop(\"right\", None)\n",
        "                e['transcription'] = transcriptions[e['id']]\n",
        "                e['mocap_hand'] = get_mocap_hand(path_to_mocap_hand, mocap_f + '.txt', e['start'], e['end'])\n",
        "                e['mocap_rot'] = get_mocap_rot(path_to_mocap_rot, mocap_f + '.txt', e['start'], e['end'])\n",
        "                e['mocap_head'] = get_mocap_head(path_to_mocap_head, mocap_f + '.txt', e['start'], e['end'])\n",
        "                if e['emotion'] in emotions_used:\n",
        "                    if e['id'] not in ids:\n",
        "                        data.append(e)\n",
        "                        ids[e['id']] = 1\n",
        "\n",
        "\n",
        "    sort_key = get_field(data, \"id\")\n",
        "    return np.array(data)[np.argsort(sort_key)]\n",
        "\n",
        "data = read_iemocap_mocap()\n",
        "\n",
        "import pickle\n",
        "with open(data_path + '/./'+'iemocap_data_collected.pickle', 'wb') as handle:\n",
        "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9PO7oHw-gE6",
        "outputId": "bf4f2a0f-8b89-424f-a777-51b8b2c98df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ses01M_impro06\n",
            "Ses01M_script02_2\n",
            "Ses01F_script01_1\n",
            "Ses01F_script03_2\n",
            "Ses01M_script01_1\n",
            "Ses01M_impro02\n",
            "Ses01M_script01_3\n",
            "Ses01F_script01_2\n",
            "Ses01M_impro03\n",
            "Ses01F_impro06\n",
            "Ses01M_script01_2\n",
            "Ses01M_impro01\n",
            "Ses01F_script03_1\n",
            "Ses01F_script02_2\n",
            "Ses01M_impro04\n",
            "Ses01F_impro03\n",
            "Ses01F_script02_1\n",
            "Ses01F_impro01\n",
            "Ses01M_script03_1\n",
            "Ses01M_impro05\n",
            "Ses01F_impro05\n",
            "Ses01F_impro02\n",
            "Ses01M_script03_2\n",
            "Ses01F_script01_3\n",
            "Ses01F_impro07\n",
            "Ses01M_script02_1\n",
            "Ses01M_impro07\n",
            "Ses01F_impro04\n",
            "Ses02M_impro01\n",
            "Ses02F_script03_2\n",
            "Ses02F_impro05\n",
            "Ses02M_script03_1\n",
            "Ses02F_impro03\n",
            "Ses02F_impro08\n",
            "Ses02M_impro03\n",
            "Ses02M_impro06\n",
            "Ses02F_impro04\n",
            "Ses02F_impro06\n",
            "Ses02F_script03_1\n",
            "Ses02F_script02_1\n",
            "Ses02M_script01_3\n",
            "Ses02F_impro07\n",
            "Ses02M_script02_1\n",
            "Ses02F_script01_2\n",
            "Ses02F_script01_3\n",
            "Ses02F_impro02\n",
            "Ses02M_script02_2\n",
            "Ses02M_script01_2\n",
            "Ses02M_impro02\n",
            "Ses02M_impro07\n",
            "Ses02M_impro04\n",
            "Ses02F_script01_1\n",
            "Ses02F_script02_2\n",
            "Ses02M_impro08\n",
            "Ses02M_script03_2\n",
            "Ses02M_impro05\n",
            "Ses02M_script01_1\n",
            "Ses02F_impro01\n",
            "Ses03F_script02_1\n",
            "Ses03M_script03_2\n",
            "Ses03F_impro02\n",
            "Ses03M_impro05b\n",
            "Ses03M_impro08a\n",
            "Ses03M_impro08b\n",
            "Ses03M_impro01\n",
            "Ses03M_script02_1\n",
            "Ses03F_impro06\n",
            "Ses03M_script01_1\n",
            "Ses03F_impro01\n",
            "Ses03F_script01_3\n",
            "Ses03M_script02_2\n",
            "Ses03M_impro04\n",
            "Ses03M_impro07\n",
            "Ses03F_script01_2\n",
            "Ses03M_script01_2\n",
            "Ses03M_impro06\n",
            "Ses03F_impro07\n",
            "Ses03M_impro03\n",
            "Ses03F_impro08\n",
            "Ses03F_impro05\n",
            "Ses03F_script01_1\n",
            "Ses03F_impro04\n",
            "Ses03M_script03_1\n",
            "Ses03F_script03_1\n",
            "Ses03F_impro03\n",
            "Ses03M_impro02\n",
            "Ses03M_script01_3\n",
            "Ses03M_impro05a\n",
            "Ses03F_script02_2\n",
            "Ses03F_script03_2\n",
            "Ses04F_script03_1\n",
            "Ses04M_impro02\n",
            "Ses04F_impro03\n",
            "Ses04F_script01_1\n",
            "Ses04F_script03_2\n",
            "Ses04F_impro01\n",
            "Ses04F_impro05\n",
            "Ses04M_script03_1\n",
            "Ses04M_impro04\n",
            "Ses04M_script01_1\n",
            "Ses04F_impro04\n",
            "Ses04F_script01_2\n",
            "Ses04M_script03_2\n",
            "Ses04M_script01_3\n",
            "Ses04F_impro02\n",
            "Ses04F_script02_2\n",
            "Ses04F_impro06\n",
            "Ses04F_script01_3\n",
            "Ses04F_impro07\n",
            "Ses04M_script02_2\n",
            "Ses04M_impro01\n",
            "Ses04M_script01_2\n",
            "Ses04M_impro07\n",
            "Ses04M_impro05\n",
            "Ses04M_impro08\n",
            "Ses04M_impro03\n",
            "Ses04M_impro06\n",
            "Ses04F_script02_1\n",
            "Ses04M_script02_1\n",
            "Ses04F_impro08\n",
            "Ses05F_script01_1\n",
            "Ses05M_script02_1\n",
            "Ses05F_impro01\n",
            "Ses05F_script02_1\n",
            "Ses05M_impro02\n",
            "Ses05F_script01_2\n",
            "Ses05M_script01_2\n",
            "Ses05M_impro04\n",
            "Ses05F_impro06\n",
            "Ses05M_impro07\n",
            "Ses05M_impro08\n",
            "Ses05F_impro08\n",
            "Ses05M_script01_3\n",
            "Ses05M_impro03\n",
            "Ses05M_impro06\n",
            "Ses05M_impro01\n",
            "Ses05M_script02_2\n",
            "Ses05F_impro07\n",
            "Ses05M_script01_1b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ses05F_impro04\n",
            "Ses05M_impro05\n",
            "Ses05F_script03_2\n",
            "Ses05F_impro03\n",
            "Ses05M_script03_1\n",
            "Ses05F_script02_2\n",
            "Ses05F_impro02\n",
            "Ses05F_script03_1\n",
            "Ses05M_script03_2\n",
            "Ses05F_impro05\n",
            "Ses05M_script01_1\n",
            "Ses05F_script01_3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VOICED FEATURES"
      ],
      "metadata": {
        "id": "MkznIMD4-nSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "nb_feat = 34\n",
        "nb_class = 4\n",
        "\n",
        "\n",
        "optimizer = 'Adadelta'\n",
        "\n",
        "\n",
        "emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n",
        "data_path = \"/content/drive/MyDrive/Data/\"\n",
        "sessions = ['Session1','Session2','Session3','Session4','Session5']\n",
        "framerate = 16000"
      ],
      "metadata": {
        "id": "RlwzRcnnI3BU",
        "outputId": "1058cfd8-42ae-417f-b435-5c9e529f9729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-eee044bd462c>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0memotions_used\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ang'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Session1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Session2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Session3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Session4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Session5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(data_path +'/data_collected2.pickle', 'rb') as handle:\n",
        "    data2 = pickle.load(handle)\n",
        "\n",
        "# read output label\n",
        "Y=[]\n",
        "for ses_mod in data2:\n",
        "    Y.append(ses_mod['emotion'])\n",
        "Y = label_binarize(y=Y, classes=emotions_used)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCSIAaXQ2h2i",
        "outputId": "053a0eec-92ba-4c4e-f70c-96975a4bd714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [1, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_features(frames, freq, options):\n",
        "    window_sec = 0.2\n",
        "    window_n = int(freq * window_sec)\n",
        "\n",
        "    st_f = stFeatureExtraction(frames, freq, window_n, window_n / 2)\n",
        "\n",
        "    if len(st_f.shape) > 1 and st_f.shape[1] > 2:\n",
        "        i0 = 1\n",
        "        i1 = st_f.shape[1] - 1\n",
        "        if i1 - i0 < 1:\n",
        "            i1 = i0 + 1\n",
        "\n",
        "        deriv_st_f = np.zeros((st_f.shape[0], i1 - i0), dtype=float)\n",
        "        for i in range(i0, i1):\n",
        "            i_left = i - 1\n",
        "            i_right = i + 1\n",
        "            deriv_st_f[:st_f.shape[0], i - i0] = st_f[:, i]\n",
        "        return deriv_st_f\n",
        "    elif len(st_f.shape) > 1 and st_f.shape[1] == 2:\n",
        "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
        "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
        "        return deriv_st_f\n",
        "    else:\n",
        "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
        "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
        "        return deriv_st_f\n",
        "\n",
        "# doing silence removal (already saved as npy)\n",
        "voiced_feat = []\n",
        "for ses_mod in data2:\n",
        "    x_head = ses_mod['signal']\n",
        "    seg = audiosegment.from_numpy_array(x_head, framerate)\n",
        "    voice = seg.filter_silence(0.01, 0.01)\n",
        "    st_features = calculate_features(voice.to_numpy_array(), framerate, None)\n",
        "    if st_features.shape[0] == 0:\n",
        "      print(\"Empty st_features array, skipping this segment\")\n",
        "      continue  # or return or handle the case in an appropriate way\n",
        "\n",
        "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
        "    voiced_feat.append(st_features.T)\n",
        "\n",
        "voiced_feat = np.array(voiced_feat)\n",
        "voiced_feat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl6ETTB8-nf0",
        "outputId": "728a8e10-a088-4468-b9d1-0fe5991c1b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4936, 100, 34)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('voiced_feat.npy', voiced_feat)"
      ],
      "metadata": {
        "id": "r6qABB4HcTmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST TRAIN SPLIT"
      ],
      "metadata": {
        "id": "8_c33kslMdvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X= np.load('/content/drive/MyDrive/Data/voiced_feat.npy')\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "H5GMUdZTMdbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 1 LSTM"
      ],
      "metadata": {
        "id": "GfDv_e_0G4zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def speech_model1():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(512, return_sequences=True, input_shape=(100, 34)))\n",
        "    model.add(LSTM(256, return_sequences=False))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(4))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model1 = speech_model1()\n",
        "model1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1hUYcLCG5M7",
        "outputId": "099520c3-6761-4dd2-eeec-8c55a47b6370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100, 512)          1120256   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 256)               787456    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               131584    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,041,348\n",
            "Trainable params: 2,041,348\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"best_model1.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq='epoch')\n",
        "hist1 = model1.fit(X_train, Y_train, batch_size=32, epochs=50, verbose=1, shuffle = False,callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkMTDHPE3jd7",
        "outputId": "406e8fd8-2865-4816-cbce-6cdb1619324e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3556 - accuracy: 0.3662\n",
            "Epoch 1: loss improved from inf to 1.35559, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 155s 1s/step - loss: 1.3556 - accuracy: 0.3662\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3530 - accuracy: 0.3656\n",
            "Epoch 2: loss improved from 1.35559 to 1.35304, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 152s 1s/step - loss: 1.3530 - accuracy: 0.3656\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3494 - accuracy: 0.3735\n",
            "Epoch 3: loss improved from 1.35304 to 1.34941, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 152s 1s/step - loss: 1.3494 - accuracy: 0.3735\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3712 - accuracy: 0.3671\n",
            "Epoch 4: loss did not improve from 1.34941\n",
            "104/104 [==============================] - 153s 1s/step - loss: 1.3712 - accuracy: 0.3671\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3585 - accuracy: 0.3629\n",
            "Epoch 5: loss did not improve from 1.34941\n",
            "104/104 [==============================] - 159s 2s/step - loss: 1.3585 - accuracy: 0.3629\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3532 - accuracy: 0.3735\n",
            "Epoch 6: loss did not improve from 1.34941\n",
            "104/104 [==============================] - 156s 1s/step - loss: 1.3532 - accuracy: 0.3735\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3282 - accuracy: 0.3955\n",
            "Epoch 7: loss improved from 1.34941 to 1.32822, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 155s 1s/step - loss: 1.3282 - accuracy: 0.3955\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3490 - accuracy: 0.3704\n",
            "Epoch 8: loss did not improve from 1.32822\n",
            "104/104 [==============================] - 155s 1s/step - loss: 1.3490 - accuracy: 0.3704\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2925 - accuracy: 0.4137\n",
            "Epoch 9: loss improved from 1.32822 to 1.29246, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 154s 1s/step - loss: 1.2925 - accuracy: 0.4137\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2585 - accuracy: 0.3992\n",
            "Epoch 10: loss improved from 1.29246 to 1.25845, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 157s 2s/step - loss: 1.2585 - accuracy: 0.3992\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3093 - accuracy: 0.3759\n",
            "Epoch 11: loss did not improve from 1.25845\n",
            "104/104 [==============================] - 161s 2s/step - loss: 1.3093 - accuracy: 0.3759\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2254 - accuracy: 0.3989\n",
            "Epoch 12: loss improved from 1.25845 to 1.22544, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 159s 2s/step - loss: 1.2254 - accuracy: 0.3989\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2295 - accuracy: 0.4176\n",
            "Epoch 13: loss did not improve from 1.22544\n",
            "104/104 [==============================] - 161s 2s/step - loss: 1.2295 - accuracy: 0.4176\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2191 - accuracy: 0.4212\n",
            "Epoch 14: loss improved from 1.22544 to 1.21907, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 155s 1s/step - loss: 1.2191 - accuracy: 0.4212\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2302 - accuracy: 0.4321\n",
            "Epoch 15: loss did not improve from 1.21907\n",
            "104/104 [==============================] - 155s 1s/step - loss: 1.2302 - accuracy: 0.4321\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1906 - accuracy: 0.4460\n",
            "Epoch 16: loss improved from 1.21907 to 1.19064, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 155s 1s/step - loss: 1.1906 - accuracy: 0.4460\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2774 - accuracy: 0.3979\n",
            "Epoch 17: loss did not improve from 1.19064\n",
            "104/104 [==============================] - 155s 1s/step - loss: 1.2774 - accuracy: 0.3979\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2066 - accuracy: 0.4376\n",
            "Epoch 18: loss did not improve from 1.19064\n",
            "104/104 [==============================] - 159s 2s/step - loss: 1.2066 - accuracy: 0.4376\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1773 - accuracy: 0.4478\n",
            "Epoch 19: loss improved from 1.19064 to 1.17734, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 159s 2s/step - loss: 1.1773 - accuracy: 0.4478\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1643 - accuracy: 0.4732\n",
            "Epoch 20: loss improved from 1.17734 to 1.16432, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 161s 2s/step - loss: 1.1643 - accuracy: 0.4732\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1618 - accuracy: 0.4663\n",
            "Epoch 21: loss improved from 1.16432 to 1.16184, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 160s 2s/step - loss: 1.1618 - accuracy: 0.4663\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1385 - accuracy: 0.4778\n",
            "Epoch 22: loss improved from 1.16184 to 1.13851, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 161s 2s/step - loss: 1.1385 - accuracy: 0.4778\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1285 - accuracy: 0.4881\n",
            "Epoch 23: loss improved from 1.13851 to 1.12852, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 157s 2s/step - loss: 1.1285 - accuracy: 0.4881\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1314 - accuracy: 0.4865\n",
            "Epoch 24: loss did not improve from 1.12852\n",
            "104/104 [==============================] - 156s 1s/step - loss: 1.1314 - accuracy: 0.4865\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1164 - accuracy: 0.4923\n",
            "Epoch 25: loss improved from 1.12852 to 1.11643, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 1.1164 - accuracy: 0.4923\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1130 - accuracy: 0.4944\n",
            "Epoch 26: loss improved from 1.11643 to 1.11301, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 160s 2s/step - loss: 1.1130 - accuracy: 0.4944\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1059 - accuracy: 0.4974\n",
            "Epoch 27: loss improved from 1.11301 to 1.10588, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 157s 2s/step - loss: 1.1059 - accuracy: 0.4974\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0976 - accuracy: 0.5002\n",
            "Epoch 28: loss improved from 1.10588 to 1.09764, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 159s 2s/step - loss: 1.0976 - accuracy: 0.5002\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0961 - accuracy: 0.5041\n",
            "Epoch 29: loss improved from 1.09764 to 1.09611, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 156s 2s/step - loss: 1.0961 - accuracy: 0.5041\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0814 - accuracy: 0.5135\n",
            "Epoch 30: loss improved from 1.09611 to 1.08138, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 156s 1s/step - loss: 1.0814 - accuracy: 0.5135\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0711 - accuracy: 0.5165\n",
            "Epoch 31: loss improved from 1.08138 to 1.07108, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 156s 1s/step - loss: 1.0711 - accuracy: 0.5165\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0834 - accuracy: 0.5068\n",
            "Epoch 32: loss did not improve from 1.07108\n",
            "104/104 [==============================] - 159s 2s/step - loss: 1.0834 - accuracy: 0.5068\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0593 - accuracy: 0.5201\n",
            "Epoch 33: loss improved from 1.07108 to 1.05925, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 161s 2s/step - loss: 1.0593 - accuracy: 0.5201\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0513 - accuracy: 0.5129\n",
            "Epoch 34: loss improved from 1.05925 to 1.05125, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 162s 2s/step - loss: 1.0513 - accuracy: 0.5129\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0431 - accuracy: 0.5183\n",
            "Epoch 35: loss improved from 1.05125 to 1.04314, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 156s 2s/step - loss: 1.0431 - accuracy: 0.5183\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0341 - accuracy: 0.5268\n",
            "Epoch 36: loss improved from 1.04314 to 1.03415, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 156s 2s/step - loss: 1.0341 - accuracy: 0.5268\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0232 - accuracy: 0.5340\n",
            "Epoch 37: loss improved from 1.03415 to 1.02322, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 155s 1s/step - loss: 1.0232 - accuracy: 0.5340\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.5319\n",
            "Epoch 38: loss improved from 1.02322 to 1.01576, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 154s 1s/step - loss: 1.0158 - accuracy: 0.5319\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0068 - accuracy: 0.5437\n",
            "Epoch 39: loss improved from 1.01576 to 1.00676, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 154s 1s/step - loss: 1.0068 - accuracy: 0.5437\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9984 - accuracy: 0.5395\n",
            "Epoch 40: loss improved from 1.00676 to 0.99845, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 154s 1s/step - loss: 0.9984 - accuracy: 0.5395\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9903 - accuracy: 0.5473\n",
            "Epoch 41: loss improved from 0.99845 to 0.99025, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 154s 1s/step - loss: 0.9903 - accuracy: 0.5473\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9810 - accuracy: 0.5525\n",
            "Epoch 42: loss improved from 0.99025 to 0.98095, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 156s 1s/step - loss: 0.9810 - accuracy: 0.5525\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9678 - accuracy: 0.5597\n",
            "Epoch 43: loss improved from 0.98095 to 0.96784, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.9678 - accuracy: 0.5597\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9656 - accuracy: 0.5670\n",
            "Epoch 44: loss improved from 0.96784 to 0.96558, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 154s 1s/step - loss: 0.9656 - accuracy: 0.5670\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9572 - accuracy: 0.5661\n",
            "Epoch 45: loss improved from 0.96558 to 0.95718, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 153s 1s/step - loss: 0.9572 - accuracy: 0.5661\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9405 - accuracy: 0.5773\n",
            "Epoch 46: loss improved from 0.95718 to 0.94054, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 152s 1s/step - loss: 0.9405 - accuracy: 0.5773\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9336 - accuracy: 0.5761\n",
            "Epoch 47: loss improved from 0.94054 to 0.93358, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 154s 1s/step - loss: 0.9336 - accuracy: 0.5761\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9325 - accuracy: 0.5791\n",
            "Epoch 48: loss improved from 0.93358 to 0.93247, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 152s 1s/step - loss: 0.9325 - accuracy: 0.5791\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9129 - accuracy: 0.5939\n",
            "Epoch 49: loss improved from 0.93247 to 0.91287, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 152s 1s/step - loss: 0.9129 - accuracy: 0.5939\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9079 - accuracy: 0.5993\n",
            "Epoch 50: loss improved from 0.91287 to 0.90794, saving model to best_model1.hdf5\n",
            "104/104 [==============================] - 152s 1s/step - loss: 0.9079 - accuracy: 0.5993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "Y_pred=model1.predict(X_test)\n",
        "Y_pred=np.argmax(Y_pred, axis=1)\n",
        "print('\\nConfusion Matrix\\n')\n",
        "cm = confusion_matrix(Y_test, Y_pred)\n",
        "print(cm)\n",
        "\n",
        "acc1 = hist1.history['accuracy']\n",
        "print('\\nTraining Accuracy\\n')\n",
        "print('Mean Training Accuracy',np.mean(acc1))\n",
        "print('Max Training Accuracy',max(acc1))\n",
        "\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(Y_test, Y_pred, target_names= emotions_used))\n",
        "\n",
        "print('Class Wise Accuracy\\n')\n",
        "acc=0\n",
        "for idx in range(0,4):\n",
        "  sum=0\n",
        "  for j in range(0,4):\n",
        "    sum= sum + cm[idx][j]\n",
        "  acc = cm[idx][idx] / sum\n",
        "  print(emotions_used[idx],\" : \",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueau0vpd4i5j",
        "outputId": "de55f3cf-bced-48e9-aaed-82651ff6db97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 18s 360ms/step\n",
            "\n",
            "Confusion Matrix\n",
            "\n",
            "[[109  84 144  37]\n",
            " [ 43  94 156  51]\n",
            " [ 17  59 300 175]\n",
            " [  4   4  49 303]]\n",
            "\n",
            "Training Accuracy\n",
            "\n",
            "Mean Training Accuracy 0.4784941053390503\n",
            "Max Training Accuracy 0.599334716796875\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ang       0.63      0.29      0.40       374\n",
            "         exc       0.39      0.27      0.32       344\n",
            "         neu       0.46      0.54      0.50       551\n",
            "         sad       0.54      0.84      0.65       360\n",
            "\n",
            "    accuracy                           0.49      1629\n",
            "   macro avg       0.50      0.49      0.47      1629\n",
            "weighted avg       0.50      0.49      0.47      1629\n",
            "\n",
            "Class Wise Accuracy\n",
            "\n",
            "ang  :  0.2914438502673797\n",
            "exc  :  0.27325581395348836\n",
            "neu  :  0.5444646098003629\n",
            "sad  :  0.8416666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 2 LSTM GLOBAL ATTENTION"
      ],
      "metadata": {
        "id": "GjxZys6D7qVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from keras.layers import LSTM,RNN\n",
        "from keras import regularizers, constraints, initializers, activations\n",
        "from tensorflow.keras.layers import InputSpec,Layer\n",
        "from tensorflow.keras.layers import LSTMCell\n",
        "\n",
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x\n",
        "\n",
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HEbUVx4t7z7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def global_attention_model(optimizer='adam'):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(256, return_sequences=True),input_shape=(100, 34)))\n",
        "    model.add(GlobalSelfAttention(num_heads=4,key_dim=128))\n",
        "    model.add(FeedForward(512,2048))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model2 = global_attention_model()\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7895KXkM9OJ4",
        "outputId": "edf25eca-9c8a-4c3f-a00e-d8749d5dbaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 100, 512)         595968    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_self_attention (Glob  (None, 100, 512)         1051648   \n",
            " alSelfAttention)                                                \n",
            "                                                                 \n",
            " feed_forward (FeedForward)  (None, 100, 512)          2100736   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 51200)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                3276864   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 64)               256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,025,732\n",
            "Trainable params: 7,025,604\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"best_model2.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto',  save_freq='epoch')\n",
        "hist2 = model2.fit(X_train, Y_train, batch_size=32, epochs=50, verbose=1, shuffle = False,\n",
        "                 callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFJRTVaW4Tg_",
        "outputId": "51bd3597-0c45-47e3-a9ee-5429bc1b5d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2699 - accuracy: 0.4064\n",
            "Epoch 1: loss improved from inf to 1.26987, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 173s 2s/step - loss: 1.2699 - accuracy: 0.4064\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1466 - accuracy: 0.4651\n",
            "Epoch 2: loss improved from 1.26987 to 1.14660, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 163s 2s/step - loss: 1.1466 - accuracy: 0.4651\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1458 - accuracy: 0.4681\n",
            "Epoch 3: loss improved from 1.14660 to 1.14585, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 166s 2s/step - loss: 1.1458 - accuracy: 0.4681\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1530 - accuracy: 0.4738\n",
            "Epoch 4: loss did not improve from 1.14585\n",
            "104/104 [==============================] - 161s 2s/step - loss: 1.1530 - accuracy: 0.4738\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1350 - accuracy: 0.4766\n",
            "Epoch 5: loss improved from 1.14585 to 1.13504, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 165s 2s/step - loss: 1.1350 - accuracy: 0.4766\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0956 - accuracy: 0.4950\n",
            "Epoch 6: loss improved from 1.13504 to 1.09564, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 161s 2s/step - loss: 1.0956 - accuracy: 0.4950\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0703 - accuracy: 0.5144\n",
            "Epoch 7: loss improved from 1.09564 to 1.07033, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 1.0703 - accuracy: 0.5144\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0447 - accuracy: 0.5349\n",
            "Epoch 8: loss improved from 1.07033 to 1.04470, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 1.0447 - accuracy: 0.5349\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0251 - accuracy: 0.5473\n",
            "Epoch 9: loss improved from 1.04470 to 1.02508, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 159s 2s/step - loss: 1.0251 - accuracy: 0.5473\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0056 - accuracy: 0.5630\n",
            "Epoch 10: loss improved from 1.02508 to 1.00556, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 159s 2s/step - loss: 1.0056 - accuracy: 0.5630\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9986 - accuracy: 0.5585\n",
            "Epoch 11: loss improved from 1.00556 to 0.99856, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 159s 2s/step - loss: 0.9986 - accuracy: 0.5585\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9801 - accuracy: 0.5739\n",
            "Epoch 12: loss improved from 0.99856 to 0.98014, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.9801 - accuracy: 0.5739\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9590 - accuracy: 0.5875\n",
            "Epoch 13: loss improved from 0.98014 to 0.95902, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.9590 - accuracy: 0.5875\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9423 - accuracy: 0.5918\n",
            "Epoch 14: loss improved from 0.95902 to 0.94234, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 157s 2s/step - loss: 0.9423 - accuracy: 0.5918\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9458 - accuracy: 0.5848\n",
            "Epoch 15: loss did not improve from 0.94234\n",
            "104/104 [==============================] - 157s 2s/step - loss: 0.9458 - accuracy: 0.5848\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9223 - accuracy: 0.5954\n",
            "Epoch 16: loss improved from 0.94234 to 0.92234, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 157s 2s/step - loss: 0.9223 - accuracy: 0.5954\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8968 - accuracy: 0.6181\n",
            "Epoch 17: loss improved from 0.92234 to 0.89676, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.8968 - accuracy: 0.6181\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8958 - accuracy: 0.6129\n",
            "Epoch 18: loss improved from 0.89676 to 0.89582, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 156s 2s/step - loss: 0.8958 - accuracy: 0.6129\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8593 - accuracy: 0.6326\n",
            "Epoch 19: loss improved from 0.89582 to 0.85932, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 157s 2s/step - loss: 0.8593 - accuracy: 0.6326\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8330 - accuracy: 0.6562\n",
            "Epoch 20: loss improved from 0.85932 to 0.83303, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.8330 - accuracy: 0.6562\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7936 - accuracy: 0.6737\n",
            "Epoch 21: loss improved from 0.83303 to 0.79364, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 169s 2s/step - loss: 0.7936 - accuracy: 0.6737\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9190 - accuracy: 0.6069\n",
            "Epoch 22: loss did not improve from 0.79364\n",
            "104/104 [==============================] - 164s 2s/step - loss: 0.9190 - accuracy: 0.6069\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9875 - accuracy: 0.5779\n",
            "Epoch 23: loss did not improve from 0.79364\n",
            "104/104 [==============================] - 160s 2s/step - loss: 0.9875 - accuracy: 0.5779\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9051 - accuracy: 0.6178\n",
            "Epoch 24: loss did not improve from 0.79364\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.9051 - accuracy: 0.6178\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8086 - accuracy: 0.6731\n",
            "Epoch 25: loss did not improve from 0.79364\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.8086 - accuracy: 0.6731\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7545 - accuracy: 0.6985\n",
            "Epoch 26: loss improved from 0.79364 to 0.75451, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 159s 2s/step - loss: 0.7545 - accuracy: 0.6985\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7210 - accuracy: 0.7130\n",
            "Epoch 27: loss improved from 0.75451 to 0.72103, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.7210 - accuracy: 0.7130\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.7297\n",
            "Epoch 28: loss improved from 0.72103 to 0.67456, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 159s 2s/step - loss: 0.6746 - accuracy: 0.7297\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6550 - accuracy: 0.7366\n",
            "Epoch 29: loss improved from 0.67456 to 0.65497, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 162s 2s/step - loss: 0.6550 - accuracy: 0.7366\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.7551\n",
            "Epoch 30: loss improved from 0.65497 to 0.61501, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 159s 2s/step - loss: 0.6150 - accuracy: 0.7551\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.7678\n",
            "Epoch 31: loss improved from 0.61501 to 0.59897, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 160s 2s/step - loss: 0.5990 - accuracy: 0.7678\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.7920\n",
            "Epoch 32: loss improved from 0.59897 to 0.54084, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.5408 - accuracy: 0.7920\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.8113\n",
            "Epoch 33: loss improved from 0.54084 to 0.49123, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.4912 - accuracy: 0.8113\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4786 - accuracy: 0.8140\n",
            "Epoch 34: loss improved from 0.49123 to 0.47859, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.4786 - accuracy: 0.8140\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.8074\n",
            "Epoch 35: loss did not improve from 0.47859\n",
            "104/104 [==============================] - 160s 2s/step - loss: 0.4806 - accuracy: 0.8074\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.8379\n",
            "Epoch 36: loss improved from 0.47859 to 0.41575, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.4158 - accuracy: 0.8379\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.8600\n",
            "Epoch 37: loss improved from 0.41575 to 0.36562, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 157s 2s/step - loss: 0.3656 - accuracy: 0.8600\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.8902\n",
            "Epoch 38: loss improved from 0.36562 to 0.30172, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.3017 - accuracy: 0.8902\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8645\n",
            "Epoch 39: loss did not improve from 0.30172\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.3596 - accuracy: 0.8645\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3058 - accuracy: 0.8905\n",
            "Epoch 40: loss did not improve from 0.30172\n",
            "104/104 [==============================] - 159s 2s/step - loss: 0.3058 - accuracy: 0.8905\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.9153\n",
            "Epoch 41: loss improved from 0.30172 to 0.25166, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.2517 - accuracy: 0.9153\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.2315 - accuracy: 0.9138\n",
            "Epoch 42: loss improved from 0.25166 to 0.23149, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.2315 - accuracy: 0.9138\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.9174\n",
            "Epoch 43: loss did not improve from 0.23149\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.2395 - accuracy: 0.9174\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9271\n",
            "Epoch 44: loss improved from 0.23149 to 0.20789, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.2079 - accuracy: 0.9271\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9392\n",
            "Epoch 45: loss improved from 0.20789 to 0.17671, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 157s 2s/step - loss: 0.1767 - accuracy: 0.9392\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9380\n",
            "Epoch 46: loss improved from 0.17671 to 0.16120, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 160s 2s/step - loss: 0.1612 - accuracy: 0.9380\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.1687 - accuracy: 0.9386\n",
            "Epoch 47: loss did not improve from 0.16120\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.1687 - accuracy: 0.9386\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9531\n",
            "Epoch 48: loss improved from 0.16120 to 0.14131, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 159s 2s/step - loss: 0.1413 - accuracy: 0.9531\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9634\n",
            "Epoch 49: loss improved from 0.14131 to 0.11206, saving model to best_model2.hdf5\n",
            "104/104 [==============================] - 158s 2s/step - loss: 0.1121 - accuracy: 0.9634\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9565\n",
            "Epoch 50: loss did not improve from 0.11206\n",
            "104/104 [==============================] - 156s 2s/step - loss: 0.1182 - accuracy: 0.9565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "Y_pred=model2.predict(X_test)\n",
        "Y_pred=np.argmax(Y_pred, axis=1)\n",
        "print('\\nConfusion Matrix\\n')\n",
        "\n",
        "cm = confusion_matrix(Y_test, Y_pred)\n",
        "print(cm)\n",
        "print('\\nTraining Accuracy\\n',)\n",
        "acc2 = hist2.history['accuracy']\n",
        "print('Mean Training Accuracy',np.mean(acc2))\n",
        "print('Max Training Accuracy',max(acc2))\n",
        "\n",
        "\n",
        "\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(Y_test, Y_pred, target_names= emotions_used))\n",
        "\n",
        "\n",
        "# Calculate the accuracy for each one of our classes\n",
        "print('Class Wise Accuracy\\n')\n",
        "acc=0\n",
        "for idx in range(0,4):\n",
        "  sum=0\n",
        "  for j in range(0,4):\n",
        "    sum= sum + cm[idx][j]\n",
        "  acc = cm[idx][idx] / sum\n",
        "  print(emotions_used[idx],\" : \",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL_ID_rm4UXk",
        "outputId": "b94f7aa4-3a7d-41c5-9770-796302fdeebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 24s 469ms/step\n",
            "\n",
            "Confusion Matrix\n",
            "\n",
            "[[113 111  96  54]\n",
            " [ 28 173  99  44]\n",
            " [ 36  93 265 157]\n",
            " [  7  12  54 287]]\n",
            "\n",
            "Training Accuracy\n",
            "\n",
            "Mean Training Accuracy 0.7087390398979188\n",
            "Max Training Accuracy 0.9634109735488892\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ang       0.61      0.30      0.41       374\n",
            "         exc       0.44      0.50      0.47       344\n",
            "         neu       0.52      0.48      0.50       551\n",
            "         sad       0.53      0.80      0.64       360\n",
            "\n",
            "    accuracy                           0.51      1629\n",
            "   macro avg       0.53      0.52      0.50      1629\n",
            "weighted avg       0.53      0.51      0.50      1629\n",
            "\n",
            "Class Wise Accuracy\n",
            "\n",
            "ang  :  0.30213903743315507\n",
            "exc  :  0.502906976744186\n",
            "neu  :  0.4809437386569873\n",
            "sad  :  0.7972222222222223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 3 SIMPLE LSTM ATTENTION"
      ],
      "metadata": {
        "id": "wnNrzdDj9fQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from keras.layers import LSTM,RNN\n",
        "from keras import regularizers, constraints, initializers, activations\n",
        "from tensorflow.keras.layers import InputSpec,Layer\n",
        "from tensorflow.keras.layers import LSTMCell\n",
        "\n",
        "# Add attention layer to the deep learning network\n",
        "class attention(Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(attention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1),\n",
        "                               initializer='random_normal', trainable=True)\n",
        "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1),\n",
        "                               initializer='zeros', trainable=True)\n",
        "        super(attention, self).build(input_shape)\n",
        "\n",
        "    def call(self,x):\n",
        "        # Alignment scores. Pass them through tanh function\n",
        "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
        "        # Remove dimension of size 1\n",
        "        e = K.squeeze(e, axis=-1)\n",
        "        # Compute the weights\n",
        "        alpha = K.softmax(e)\n",
        "        # Reshape to tensorFlow format\n",
        "        alpha = K.expand_dims(alpha, axis=-1)\n",
        "        # Compute the context vector\n",
        "        context = x * alpha\n",
        "        context = K.sum(context, axis=1)\n",
        "        return context\n"
      ],
      "metadata": {
        "id": "VoAQFS5l9liS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, SimpleRNN, LSTM, Bidirectional\n",
        "def LSTMattention(hidden_units, dense_units, input_shape, activation):\n",
        "    mainmodel=Sequential()\n",
        "    x=Input(shape=input_shape)\n",
        "    BiLSTM_layer = Bidirectional(LSTM(hidden_units, return_sequences=True))(x)\n",
        "    attention_layer = attention()(BiLSTM_layer)\n",
        "    outputs=Dense(dense_units, trainable=True, activation=activation)(attention_layer)\n",
        "    model=Model(x,outputs)\n",
        "    mainmodel.add(model)\n",
        "    mainmodel.add(Dense(512, activation='relu'))\n",
        "    mainmodel.add(Dense(4, activation='softmax'))\n",
        "\n",
        "    mainmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    return mainmodel\n",
        "\n",
        "model3 = LSTMattention(hidden_units=128, dense_units=4,input_shape=(100,34), activation='tanh')\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BLipVuG9s5_",
        "outputId": "1d3c114c-5074-4cca-a22b-ae682621dba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " model_1 (Functional)        (None, 4)                 168296    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               2560      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 172,908\n",
            "Trainable params: 172,908\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"best_model3.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto',  save_freq='epoch')\n",
        "hist3 = model3.fit(X_train, Y_train, batch_size=32, epochs=50, verbose=1, shuffle = False,\n",
        "                 callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTbl6Hle7V0w",
        "outputId": "2b158b1d-4465-473a-d5a3-6a72840cd042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2451 - accuracy: 0.4276\n",
            "Epoch 1: loss improved from inf to 1.24513, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 42s 293ms/step - loss: 1.2451 - accuracy: 0.4276\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1702 - accuracy: 0.4599\n",
            "Epoch 2: loss improved from 1.24513 to 1.17022, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 296ms/step - loss: 1.1702 - accuracy: 0.4599\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1396 - accuracy: 0.4681\n",
            "Epoch 3: loss improved from 1.17022 to 1.13960, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 298ms/step - loss: 1.1396 - accuracy: 0.4681\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1161 - accuracy: 0.4871\n",
            "Epoch 4: loss improved from 1.13960 to 1.11607, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 294ms/step - loss: 1.1161 - accuracy: 0.4871\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1042 - accuracy: 0.4986\n",
            "Epoch 5: loss improved from 1.11607 to 1.10416, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 294ms/step - loss: 1.1042 - accuracy: 0.4986\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0902 - accuracy: 0.5101\n",
            "Epoch 6: loss improved from 1.10416 to 1.09019, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 294ms/step - loss: 1.0902 - accuracy: 0.5101\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0775 - accuracy: 0.5110\n",
            "Epoch 7: loss improved from 1.09019 to 1.07752, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 1.0775 - accuracy: 0.5110\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0688 - accuracy: 0.5237\n",
            "Epoch 8: loss improved from 1.07752 to 1.06884, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 1.0688 - accuracy: 0.5237\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0582 - accuracy: 0.5249\n",
            "Epoch 9: loss improved from 1.06884 to 1.05819, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 1.0582 - accuracy: 0.5249\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0497 - accuracy: 0.5277\n",
            "Epoch 10: loss improved from 1.05819 to 1.04969, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 299ms/step - loss: 1.0497 - accuracy: 0.5277\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0431 - accuracy: 0.5337\n",
            "Epoch 11: loss improved from 1.04969 to 1.04306, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 55s 528ms/step - loss: 1.0431 - accuracy: 0.5337\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0345 - accuracy: 0.5367\n",
            "Epoch 12: loss improved from 1.04306 to 1.03445, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 1.0345 - accuracy: 0.5367\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0258 - accuracy: 0.5410\n",
            "Epoch 13: loss improved from 1.03445 to 1.02581, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 295ms/step - loss: 1.0258 - accuracy: 0.5410\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0148 - accuracy: 0.5540\n",
            "Epoch 14: loss improved from 1.02581 to 1.01484, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 297ms/step - loss: 1.0148 - accuracy: 0.5540\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0025 - accuracy: 0.5552\n",
            "Epoch 15: loss improved from 1.01484 to 1.00253, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 1.0025 - accuracy: 0.5552\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9968 - accuracy: 0.5558\n",
            "Epoch 16: loss improved from 1.00253 to 0.99678, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.9968 - accuracy: 0.5558\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9869 - accuracy: 0.5640\n",
            "Epoch 17: loss improved from 0.99678 to 0.98692, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 32s 311ms/step - loss: 0.9869 - accuracy: 0.5640\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9795 - accuracy: 0.5697\n",
            "Epoch 18: loss improved from 0.98692 to 0.97952, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 297ms/step - loss: 0.9795 - accuracy: 0.5697\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9693 - accuracy: 0.5779\n",
            "Epoch 19: loss improved from 0.97952 to 0.96927, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 296ms/step - loss: 0.9693 - accuracy: 0.5779\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9451 - accuracy: 0.5888\n",
            "Epoch 20: loss improved from 0.96927 to 0.94513, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.9451 - accuracy: 0.5888\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9333 - accuracy: 0.5972\n",
            "Epoch 21: loss improved from 0.94513 to 0.93332, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 33s 316ms/step - loss: 0.9333 - accuracy: 0.5972\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9296 - accuracy: 0.5951\n",
            "Epoch 22: loss improved from 0.93332 to 0.92957, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.9296 - accuracy: 0.5951\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9177 - accuracy: 0.5996\n",
            "Epoch 23: loss improved from 0.92957 to 0.91768, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.9177 - accuracy: 0.5996\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8998 - accuracy: 0.6075\n",
            "Epoch 24: loss improved from 0.91768 to 0.89980, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.8998 - accuracy: 0.6075\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8704 - accuracy: 0.6244\n",
            "Epoch 25: loss improved from 0.89980 to 0.87045, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.8704 - accuracy: 0.6244\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8608 - accuracy: 0.6396\n",
            "Epoch 26: loss improved from 0.87045 to 0.86083, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.8608 - accuracy: 0.6396\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8506 - accuracy: 0.6405\n",
            "Epoch 27: loss improved from 0.86083 to 0.85056, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.8506 - accuracy: 0.6405\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8410 - accuracy: 0.6492\n",
            "Epoch 28: loss improved from 0.85056 to 0.84096, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 294ms/step - loss: 0.8410 - accuracy: 0.6492\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8099 - accuracy: 0.6556\n",
            "Epoch 29: loss improved from 0.84096 to 0.80987, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.8099 - accuracy: 0.6556\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8081 - accuracy: 0.6650\n",
            "Epoch 30: loss improved from 0.80987 to 0.80812, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 294ms/step - loss: 0.8081 - accuracy: 0.6650\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7842 - accuracy: 0.6680\n",
            "Epoch 31: loss improved from 0.80812 to 0.78416, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 295ms/step - loss: 0.7842 - accuracy: 0.6680\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7605 - accuracy: 0.6767\n",
            "Epoch 32: loss improved from 0.78416 to 0.76046, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.7605 - accuracy: 0.6767\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7631 - accuracy: 0.6795\n",
            "Epoch 33: loss did not improve from 0.76046\n",
            "104/104 [==============================] - 31s 296ms/step - loss: 0.7631 - accuracy: 0.6795\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7367 - accuracy: 0.6907\n",
            "Epoch 34: loss improved from 0.76046 to 0.73666, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 296ms/step - loss: 0.7367 - accuracy: 0.6907\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8633 - accuracy: 0.6374\n",
            "Epoch 35: loss did not improve from 0.73666\n",
            "104/104 [==============================] - 31s 297ms/step - loss: 0.8633 - accuracy: 0.6374\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7679 - accuracy: 0.6713\n",
            "Epoch 36: loss did not improve from 0.73666\n",
            "104/104 [==============================] - 31s 297ms/step - loss: 0.7679 - accuracy: 0.6713\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7081 - accuracy: 0.7043\n",
            "Epoch 37: loss improved from 0.73666 to 0.70806, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 296ms/step - loss: 0.7081 - accuracy: 0.7043\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6629 - accuracy: 0.7260\n",
            "Epoch 38: loss improved from 0.70806 to 0.66290, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.6629 - accuracy: 0.7260\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6347 - accuracy: 0.7430\n",
            "Epoch 39: loss improved from 0.66290 to 0.63475, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.6347 - accuracy: 0.7430\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.7418\n",
            "Epoch 40: loss improved from 0.63475 to 0.62091, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 294ms/step - loss: 0.6209 - accuracy: 0.7418\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6878 - accuracy: 0.7167\n",
            "Epoch 41: loss did not improve from 0.62091\n",
            "104/104 [==============================] - 31s 295ms/step - loss: 0.6878 - accuracy: 0.7167\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6293 - accuracy: 0.7372\n",
            "Epoch 42: loss did not improve from 0.62091\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.6293 - accuracy: 0.7372\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5786 - accuracy: 0.7602\n",
            "Epoch 43: loss improved from 0.62091 to 0.57864, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.5786 - accuracy: 0.7602\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5524 - accuracy: 0.7756\n",
            "Epoch 44: loss improved from 0.57864 to 0.55238, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 295ms/step - loss: 0.5524 - accuracy: 0.7756\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5332 - accuracy: 0.7832\n",
            "Epoch 45: loss improved from 0.55238 to 0.53319, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.5332 - accuracy: 0.7832\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.7672\n",
            "Epoch 46: loss did not improve from 0.53319\n",
            "104/104 [==============================] - 31s 294ms/step - loss: 0.5636 - accuracy: 0.7672\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.7774\n",
            "Epoch 47: loss did not improve from 0.53319\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.5358 - accuracy: 0.7774\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5033 - accuracy: 0.7971\n",
            "Epoch 48: loss improved from 0.53319 to 0.50332, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.5033 - accuracy: 0.7971\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4945 - accuracy: 0.7998\n",
            "Epoch 49: loss improved from 0.50332 to 0.49451, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 294ms/step - loss: 0.4945 - accuracy: 0.7998\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4669 - accuracy: 0.8089\n",
            "Epoch 50: loss improved from 0.49451 to 0.46688, saving model to best_model3.hdf5\n",
            "104/104 [==============================] - 31s 295ms/step - loss: 0.4669 - accuracy: 0.8089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "Y_pred=model3.predict(X_test)\n",
        "Y_pred=np.argmax(Y_pred, axis=1)\n",
        "Y_test=np.argmax(Y_test, axis=1)\n",
        "cm = confusion_matrix(Y_test, Y_pred)\n",
        "print('\\nConfusion Matrix\\n')\n",
        "print(cm)\n",
        "\n",
        "acc3 = hist3.history['accuracy']\n",
        "print('\\nTraining Accuracy\\n',)\n",
        "print('Mean Training Accuracy',np.mean(acc3))\n",
        "print('Max Training Accuracy',max(acc3))\n",
        "\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(Y_test, Y_pred, target_names= emotions_used))\n",
        "\n",
        "# Calculate the accuracy for each one of our classes\n",
        "\n",
        "print('Class Wise Accuracy\\n')\n",
        "acc=0\n",
        "for idx in range(0,4):\n",
        "  sum=0\n",
        "  for j in range(0,4):\n",
        "    sum= sum + cm[idx][j]\n",
        "  acc = cm[idx][idx] / sum\n",
        "  print(emotions_used[idx],\" : \",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ5Kcmxt7LmN",
        "outputId": "7c847082-d246-4c48-98cb-5bb17f1f1ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 9s 169ms/step\n",
            "\n",
            "Confusion Matrix\n",
            "\n",
            "[[181  70 116   7]\n",
            " [ 50 141 133  20]\n",
            " [ 50  56 348  97]\n",
            " [ 11  16  79 254]]\n",
            "\n",
            "Training Accuracy\n",
            "\n",
            "Mean Training Accuracy 0.6290232855081558\n",
            "Max Training Accuracy 0.8088902235031128\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ang       0.62      0.48      0.54       374\n",
            "         exc       0.50      0.41      0.45       344\n",
            "         neu       0.51      0.63      0.57       551\n",
            "         sad       0.67      0.71      0.69       360\n",
            "\n",
            "    accuracy                           0.57      1629\n",
            "   macro avg       0.58      0.56      0.56      1629\n",
            "weighted avg       0.57      0.57      0.56      1629\n",
            "\n",
            "Class Wise Accuracy\n",
            "\n",
            "ang  :  0.4839572192513369\n",
            "exc  :  0.40988372093023256\n",
            "neu  :  0.631578947368421\n",
            "sad  :  0.7055555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 3 BUT SAME"
      ],
      "metadata": {
        "id": "6FTgKCAhELTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, SimpleRNN, LSTM, Bidirectional\n",
        "def LSTMattention(hidden_units, dense_units, input_shape, activation):\n",
        "    x=Input(shape=input_shape)\n",
        "    BiLSTM_layer = Bidirectional(LSTM(hidden_units, return_sequences=True))(x)\n",
        "    attention_layer = attention()(BiLSTM_layer)\n",
        "    outputs=Dense(dense_units, trainable=True, activation=activation)(attention_layer)\n",
        "    dense_layer1=Dense(512, activation='relu')(outputs)\n",
        "    dense_layer2 = Dense(4, activation='softmax')(dense_layer1)\n",
        "    model=Model(x,dense_layer2)\n",
        "\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model31 = LSTMattention(hidden_units=128, dense_units=4,input_shape=(100,34), activation='tanh')\n",
        "model31.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XUqta6t-pzm",
        "outputId": "6c7adaa7-1fc4-41bf-f24d-25c4fdc7029e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 100, 34)]         0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 100, 256)         166912    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " attention_2 (attention)     (None, 256)               356       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               2560      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 172,908\n",
            "Trainable params: 172,908\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"best_model31.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto',  save_freq='epoch')\n",
        "hist3 = model31.fit(X_train, Y_train, batch_size=32, epochs=50, verbose=1, shuffle = False,\n",
        "                 callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUyxUMHfDlzJ",
        "outputId": "06043502-ca5e-4ec3-ee57-d639b22e7de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1463 - accuracy: 0.4708\n",
            "Epoch 1: loss improved from inf to 1.14628, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 41s 392ms/step - loss: 1.1463 - accuracy: 0.4708\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1299 - accuracy: 0.4766\n",
            "Epoch 2: loss improved from 1.14628 to 1.12994, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 1.1299 - accuracy: 0.4766\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1183 - accuracy: 0.4859\n",
            "Epoch 3: loss improved from 1.12994 to 1.11828, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 31s 302ms/step - loss: 1.1183 - accuracy: 0.4859\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1070 - accuracy: 0.4995\n",
            "Epoch 4: loss improved from 1.11828 to 1.10695, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 31s 295ms/step - loss: 1.1070 - accuracy: 0.4995\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0940 - accuracy: 0.5095\n",
            "Epoch 5: loss improved from 1.10695 to 1.09397, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 1.0940 - accuracy: 0.5095\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0826 - accuracy: 0.5122\n",
            "Epoch 6: loss improved from 1.09397 to 1.08259, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 1.0826 - accuracy: 0.5122\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0709 - accuracy: 0.5168\n",
            "Epoch 7: loss improved from 1.08259 to 1.07094, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 1.0709 - accuracy: 0.5168\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0603 - accuracy: 0.5243\n",
            "Epoch 8: loss improved from 1.07094 to 1.06032, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 31s 298ms/step - loss: 1.0603 - accuracy: 0.5243\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0514 - accuracy: 0.5289\n",
            "Epoch 9: loss improved from 1.06032 to 1.05142, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 1.0514 - accuracy: 0.5289\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0394 - accuracy: 0.5349\n",
            "Epoch 10: loss improved from 1.05142 to 1.03937, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 1.0394 - accuracy: 0.5349\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0285 - accuracy: 0.5422\n",
            "Epoch 11: loss improved from 1.03937 to 1.02848, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 38s 364ms/step - loss: 1.0285 - accuracy: 0.5422\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0073 - accuracy: 0.5582\n",
            "Epoch 12: loss improved from 1.02848 to 1.00731, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 1.0073 - accuracy: 0.5582\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9895 - accuracy: 0.5658\n",
            "Epoch 13: loss improved from 1.00731 to 0.98952, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.9895 - accuracy: 0.5658\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9725 - accuracy: 0.5788\n",
            "Epoch 14: loss improved from 0.98952 to 0.97246, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 0.9725 - accuracy: 0.5788\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9557 - accuracy: 0.5845\n",
            "Epoch 15: loss improved from 0.97246 to 0.95566, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 0.9557 - accuracy: 0.5845\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9394 - accuracy: 0.5894\n",
            "Epoch 16: loss improved from 0.95566 to 0.93938, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 288ms/step - loss: 0.9394 - accuracy: 0.5894\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9162 - accuracy: 0.6084\n",
            "Epoch 17: loss improved from 0.93938 to 0.91619, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.9162 - accuracy: 0.6084\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8998 - accuracy: 0.6117\n",
            "Epoch 18: loss improved from 0.91619 to 0.89981, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.8998 - accuracy: 0.6117\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8690 - accuracy: 0.6287\n",
            "Epoch 19: loss improved from 0.89981 to 0.86901, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 31s 296ms/step - loss: 0.8690 - accuracy: 0.6287\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8633 - accuracy: 0.6302\n",
            "Epoch 20: loss improved from 0.86901 to 0.86329, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.8633 - accuracy: 0.6302\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8491 - accuracy: 0.6402\n",
            "Epoch 21: loss improved from 0.86329 to 0.84912, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.8491 - accuracy: 0.6402\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8386 - accuracy: 0.6414\n",
            "Epoch 22: loss improved from 0.84912 to 0.83857, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.8386 - accuracy: 0.6414\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8092 - accuracy: 0.6489\n",
            "Epoch 23: loss improved from 0.83857 to 0.80922, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.8092 - accuracy: 0.6489\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7870 - accuracy: 0.6701\n",
            "Epoch 24: loss improved from 0.80922 to 0.78697, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.7870 - accuracy: 0.6701\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7775 - accuracy: 0.6725\n",
            "Epoch 25: loss improved from 0.78697 to 0.77751, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.7775 - accuracy: 0.6725\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7531 - accuracy: 0.6813\n",
            "Epoch 26: loss improved from 0.77751 to 0.75312, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 0.7531 - accuracy: 0.6813\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7458 - accuracy: 0.6831\n",
            "Epoch 27: loss improved from 0.75312 to 0.74579, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 0.7458 - accuracy: 0.6831\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7480 - accuracy: 0.6819\n",
            "Epoch 28: loss did not improve from 0.74579\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 0.7480 - accuracy: 0.6819\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7146 - accuracy: 0.6970\n",
            "Epoch 29: loss improved from 0.74579 to 0.71457, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.7146 - accuracy: 0.6970\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7161 - accuracy: 0.6922\n",
            "Epoch 30: loss did not improve from 0.71457\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.7161 - accuracy: 0.6922\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6634 - accuracy: 0.7194\n",
            "Epoch 31: loss improved from 0.71457 to 0.66335, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 0.6634 - accuracy: 0.7194\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6509 - accuracy: 0.7306\n",
            "Epoch 32: loss improved from 0.66335 to 0.65090, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.6509 - accuracy: 0.7306\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6255 - accuracy: 0.7390\n",
            "Epoch 33: loss improved from 0.65090 to 0.62554, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.6255 - accuracy: 0.7390\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.7587\n",
            "Epoch 34: loss improved from 0.62554 to 0.60467, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.6047 - accuracy: 0.7587\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5945 - accuracy: 0.7653\n",
            "Epoch 35: loss improved from 0.60467 to 0.59452, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.5945 - accuracy: 0.7653\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.7578\n",
            "Epoch 36: loss did not improve from 0.59452\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.6047 - accuracy: 0.7578\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5539 - accuracy: 0.7799\n",
            "Epoch 37: loss improved from 0.59452 to 0.55386, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.5539 - accuracy: 0.7799\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.7862\n",
            "Epoch 38: loss improved from 0.55386 to 0.52872, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.5287 - accuracy: 0.7862\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.7796\n",
            "Epoch 39: loss did not improve from 0.52872\n",
            "104/104 [==============================] - 30s 287ms/step - loss: 0.5374 - accuracy: 0.7796\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5227 - accuracy: 0.7944\n",
            "Epoch 40: loss improved from 0.52872 to 0.52267, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.5227 - accuracy: 0.7944\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.8113\n",
            "Epoch 41: loss improved from 0.52267 to 0.46824, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.4682 - accuracy: 0.8113\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.8219\n",
            "Epoch 42: loss improved from 0.46824 to 0.45290, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.4529 - accuracy: 0.8219\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.8116\n",
            "Epoch 43: loss did not improve from 0.45290\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.4567 - accuracy: 0.8116\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4494 - accuracy: 0.8261\n",
            "Epoch 44: loss improved from 0.45290 to 0.44940, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.4494 - accuracy: 0.8261\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.8031\n",
            "Epoch 45: loss did not improve from 0.44940\n",
            "104/104 [==============================] - 30s 286ms/step - loss: 0.4977 - accuracy: 0.8031\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.8403\n",
            "Epoch 46: loss improved from 0.44940 to 0.41581, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 31s 292ms/step - loss: 0.4158 - accuracy: 0.8403\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.8319\n",
            "Epoch 47: loss did not improve from 0.41581\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 0.4292 - accuracy: 0.8319\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8521\n",
            "Epoch 48: loss improved from 0.41581 to 0.38303, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.3830 - accuracy: 0.8521\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.8497\n",
            "Epoch 49: loss did not improve from 0.38303\n",
            "104/104 [==============================] - 30s 285ms/step - loss: 0.3904 - accuracy: 0.8497\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.8603\n",
            "Epoch 50: loss improved from 0.38303 to 0.36715, saving model to best_model31.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 0.3671 - accuracy: 0.8603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "Y_pred=model31.predict(X_test)\n",
        "Y_pred=np.argmax(Y_pred, axis=1)\n",
        "\n",
        "cm = confusion_matrix(Y_test, Y_pred)\n",
        "print('\\nConfusion Matrix\\n')\n",
        "print(cm)\n",
        "\n",
        "acc3 = hist3.history['accuracy']\n",
        "print('\\nTraining Accuracy\\n',)\n",
        "print('Mean Training Accuracy',np.mean(acc3))\n",
        "print('Max Training Accuracy',max(acc3))\n",
        "\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(Y_test, Y_pred, target_names= emotions_used))\n",
        "\n",
        "# Calculate the accuracy for each one of our classes\n",
        "\n",
        "print('Class Wise Accuracy\\n')\n",
        "acc=0\n",
        "for idx in range(0,4):\n",
        "  sum=0\n",
        "  for j in range(0,4):\n",
        "    sum= sum + cm[idx][j]\n",
        "  acc = cm[idx][idx] / sum\n",
        "  print(emotions_used[idx],\" : \",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MK1gF34DywV",
        "outputId": "aea7ad39-7692-42c1-bd74-983a37083e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 10s 201ms/step\n",
            "\n",
            "Confusion Matrix\n",
            "\n",
            "[[177  94  89  14]\n",
            " [ 56 203  68  17]\n",
            " [ 43 134 291  83]\n",
            " [ 16  31  74 239]]\n",
            "\n",
            "Training Accuracy\n",
            "\n",
            "Mean Training Accuracy 0.6717024451494217\n",
            "Max Training Accuracy 0.860296368598938\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ang       0.61      0.47      0.53       374\n",
            "         exc       0.44      0.59      0.50       344\n",
            "         neu       0.56      0.53      0.54       551\n",
            "         sad       0.68      0.66      0.67       360\n",
            "\n",
            "    accuracy                           0.56      1629\n",
            "   macro avg       0.57      0.56      0.56      1629\n",
            "weighted avg       0.57      0.56      0.56      1629\n",
            "\n",
            "Class Wise Accuracy\n",
            "\n",
            "ang  :  0.4732620320855615\n",
            "exc  :  0.5901162790697675\n",
            "neu  :  0.5281306715063521\n",
            "sad  :  0.6638888888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 4 WITHOUT OUTPUT LAYER"
      ],
      "metadata": {
        "id": "q1fiRfzaEORf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, SimpleRNN, LSTM, Bidirectional\n",
        "def LSTM_attention_NoDense4(hidden_units, dense_units, input_shape, activation):\n",
        "    x=Input(shape=input_shape)\n",
        "    BiLSTM_layer = Bidirectional(LSTM(hidden_units, return_sequences=True))(x)\n",
        "    attention_layer = attention()(BiLSTM_layer)\n",
        "    dense_layer1=Dense(512, activation='relu')(attention_layer)\n",
        "    dense_layer2 = Dense(4, activation='softmax')(dense_layer1)\n",
        "    model=Model(x,dense_layer2)\n",
        "\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model4 = LSTM_attention_NoDense4(hidden_units=128, dense_units=4,input_shape=(100,34), activation='tanh')\n",
        "model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScDFz7t4ER-b",
        "outputId": "254a9613-6ffc-4f85-dd2e-1045e8db871f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 100, 34)]         0         \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 100, 256)         166912    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " attention_3 (attention)     (None, 256)               356       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 300,904\n",
            "Trainable params: 300,904\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"best_model4.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto',  save_freq='epoch')\n",
        "hist4 = model4.fit(X_train, Y_train, batch_size=32, epochs=50, verbose=1, shuffle = False,\n",
        "                 callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgAJt5x8EcBS",
        "outputId": "5477d865-3847-41c6-d0dc-f5b7e3731f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2806 - accuracy: 0.4034\n",
            "Epoch 1: loss improved from inf to 1.28064, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 35s 291ms/step - loss: 1.2806 - accuracy: 0.4034\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1676 - accuracy: 0.4530\n",
            "Epoch 2: loss improved from 1.28064 to 1.16763, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 1.1676 - accuracy: 0.4530\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1363 - accuracy: 0.4751\n",
            "Epoch 3: loss improved from 1.16763 to 1.13633, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 1.1363 - accuracy: 0.4751\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1144 - accuracy: 0.4890\n",
            "Epoch 4: loss improved from 1.13633 to 1.11439, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 1.1144 - accuracy: 0.4890\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0974 - accuracy: 0.5089\n",
            "Epoch 5: loss improved from 1.11439 to 1.09744, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 1.0974 - accuracy: 0.5089\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0782 - accuracy: 0.5098\n",
            "Epoch 6: loss improved from 1.09744 to 1.07820, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 1.0782 - accuracy: 0.5098\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0571 - accuracy: 0.5322\n",
            "Epoch 7: loss improved from 1.07820 to 1.05706, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 294ms/step - loss: 1.0571 - accuracy: 0.5322\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0355 - accuracy: 0.5422\n",
            "Epoch 8: loss improved from 1.05706 to 1.03553, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 1.0355 - accuracy: 0.5422\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0169 - accuracy: 0.5473\n",
            "Epoch 9: loss improved from 1.03553 to 1.01686, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 1.0169 - accuracy: 0.5473\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9989 - accuracy: 0.5546\n",
            "Epoch 10: loss improved from 1.01686 to 0.99888, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.9989 - accuracy: 0.5546\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9782 - accuracy: 0.5700\n",
            "Epoch 11: loss improved from 0.99888 to 0.97820, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.9782 - accuracy: 0.5700\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9557 - accuracy: 0.5836\n",
            "Epoch 12: loss improved from 0.97820 to 0.95573, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.9557 - accuracy: 0.5836\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9344 - accuracy: 0.5921\n",
            "Epoch 13: loss improved from 0.95573 to 0.93443, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.9344 - accuracy: 0.5921\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9202 - accuracy: 0.5945\n",
            "Epoch 14: loss improved from 0.93443 to 0.92017, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.9202 - accuracy: 0.5945\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.9029 - accuracy: 0.6102\n",
            "Epoch 15: loss improved from 0.92017 to 0.90290, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.9029 - accuracy: 0.6102\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8794 - accuracy: 0.6166\n",
            "Epoch 16: loss improved from 0.90290 to 0.87940, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.8794 - accuracy: 0.6166\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8542 - accuracy: 0.6250\n",
            "Epoch 17: loss improved from 0.87940 to 0.85416, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.8542 - accuracy: 0.6250\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8234 - accuracy: 0.6423\n",
            "Epoch 18: loss improved from 0.85416 to 0.82343, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.8234 - accuracy: 0.6423\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8038 - accuracy: 0.6577\n",
            "Epoch 19: loss improved from 0.82343 to 0.80379, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 292ms/step - loss: 0.8038 - accuracy: 0.6577\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7843 - accuracy: 0.6613\n",
            "Epoch 20: loss improved from 0.80379 to 0.78428, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.7843 - accuracy: 0.6613\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7644 - accuracy: 0.6643\n",
            "Epoch 21: loss improved from 0.78428 to 0.76436, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 293ms/step - loss: 0.7644 - accuracy: 0.6643\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7272 - accuracy: 0.6870\n",
            "Epoch 22: loss improved from 0.76436 to 0.72724, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 293ms/step - loss: 0.7272 - accuracy: 0.6870\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7041 - accuracy: 0.7024\n",
            "Epoch 23: loss improved from 0.72724 to 0.70409, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 294ms/step - loss: 0.7041 - accuracy: 0.7024\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6732 - accuracy: 0.7167\n",
            "Epoch 24: loss improved from 0.70409 to 0.67322, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.6732 - accuracy: 0.7167\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.7176\n",
            "Epoch 25: loss improved from 0.67322 to 0.66518, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.6652 - accuracy: 0.7176\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.6368 - accuracy: 0.7336\n",
            "Epoch 26: loss improved from 0.66518 to 0.63681, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.6368 - accuracy: 0.7336\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5928 - accuracy: 0.7517\n",
            "Epoch 27: loss improved from 0.63681 to 0.59278, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.5928 - accuracy: 0.7517\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5507 - accuracy: 0.7762\n",
            "Epoch 28: loss improved from 0.59278 to 0.55073, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.5507 - accuracy: 0.7762\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.7874\n",
            "Epoch 29: loss improved from 0.55073 to 0.53968, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 289ms/step - loss: 0.5397 - accuracy: 0.7874\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.7895\n",
            "Epoch 30: loss improved from 0.53968 to 0.52493, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.5249 - accuracy: 0.7895\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.7811\n",
            "Epoch 31: loss improved from 0.52493 to 0.52261, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 297ms/step - loss: 0.5226 - accuracy: 0.7811\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5164 - accuracy: 0.7917\n",
            "Epoch 32: loss improved from 0.52261 to 0.51638, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.5164 - accuracy: 0.7917\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4608 - accuracy: 0.8195\n",
            "Epoch 33: loss improved from 0.51638 to 0.46079, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 296ms/step - loss: 0.4608 - accuracy: 0.8195\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4233 - accuracy: 0.8340\n",
            "Epoch 34: loss improved from 0.46079 to 0.42328, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 295ms/step - loss: 0.4233 - accuracy: 0.8340\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.8391\n",
            "Epoch 35: loss improved from 0.42328 to 0.41260, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.4126 - accuracy: 0.8391\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.8518\n",
            "Epoch 36: loss improved from 0.41260 to 0.37394, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.3739 - accuracy: 0.8518\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3709 - accuracy: 0.8573\n",
            "Epoch 37: loss improved from 0.37394 to 0.37086, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.3709 - accuracy: 0.8573\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.8624\n",
            "Epoch 38: loss improved from 0.37086 to 0.36228, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.3623 - accuracy: 0.8624\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.8721\n",
            "Epoch 39: loss improved from 0.36228 to 0.33827, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 292ms/step - loss: 0.3383 - accuracy: 0.8721\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.8657\n",
            "Epoch 40: loss did not improve from 0.33827\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.3448 - accuracy: 0.8657\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.3078 - accuracy: 0.8818\n",
            "Epoch 41: loss improved from 0.33827 to 0.30781, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.3078 - accuracy: 0.8818\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.8963\n",
            "Epoch 42: loss improved from 0.30781 to 0.27784, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 293ms/step - loss: 0.2778 - accuracy: 0.8963\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.2630 - accuracy: 0.8981\n",
            "Epoch 43: loss improved from 0.27784 to 0.26297, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 295ms/step - loss: 0.2630 - accuracy: 0.8981\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.2667 - accuracy: 0.9032\n",
            "Epoch 44: loss did not improve from 0.26297\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.2667 - accuracy: 0.9032\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.8939\n",
            "Epoch 45: loss improved from 0.26297 to 0.26194, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 293ms/step - loss: 0.2619 - accuracy: 0.8939\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.2506 - accuracy: 0.9105\n",
            "Epoch 46: loss improved from 0.26194 to 0.25061, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 295ms/step - loss: 0.2506 - accuracy: 0.9105\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 0.9193\n",
            "Epoch 47: loss improved from 0.25061 to 0.21445, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 31s 295ms/step - loss: 0.2144 - accuracy: 0.9193\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.9392\n",
            "Epoch 48: loss improved from 0.21445 to 0.17603, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 291ms/step - loss: 0.1760 - accuracy: 0.9392\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.9422\n",
            "Epoch 49: loss improved from 0.17603 to 0.16749, saving model to best_model4.hdf5\n",
            "104/104 [==============================] - 30s 290ms/step - loss: 0.1675 - accuracy: 0.9422\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.9205\n",
            "Epoch 50: loss did not improve from 0.16749\n",
            "104/104 [==============================] - 31s 294ms/step - loss: 0.2266 - accuracy: 0.9205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "Y_pred=model4.predict(X_test)\n",
        "Y_pred=np.argmax(Y_pred, axis=1)\n",
        "\n",
        "cm = confusion_matrix(Y_test, Y_pred)\n",
        "print('\\nConfusion Matrix\\n')\n",
        "print(cm)\n",
        "\n",
        "acc4 = hist4.history['accuracy']\n",
        "print('\\nTraining Accuracy\\n',)\n",
        "print('Mean Training Accuracy',np.mean(acc4))\n",
        "print('Max Training Accuracy',max(acc4))\n",
        "\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(Y_test, Y_pred, target_names= emotions_used))\n",
        "\n",
        "# Calculate the accuracy for each one of our classes\n",
        "\n",
        "print('Class Wise Accuracy\\n')\n",
        "acc=0\n",
        "for idx in range(0,4):\n",
        "  sum=0\n",
        "  for j in range(0,4):\n",
        "    sum= sum + cm[idx][j]\n",
        "  acc = cm[idx][idx] / sum\n",
        "  print(emotions_used[idx],\" : \",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chW3-BX8EhwI",
        "outputId": "d02f322b-b562-407e-8db3-0358fa155642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 9s 175ms/step\n",
            "\n",
            "Confusion Matrix\n",
            "\n",
            "[[166  87 114   7]\n",
            " [ 53 172 100  19]\n",
            " [ 50  85 349  67]\n",
            " [ 13  21 100 226]]\n",
            "\n",
            "Training Accuracy\n",
            "\n",
            "Mean Training Accuracy 0.7194980347156524\n",
            "Max Training Accuracy 0.942243754863739\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ang       0.59      0.44      0.51       374\n",
            "         exc       0.47      0.50      0.49       344\n",
            "         neu       0.53      0.63      0.57       551\n",
            "         sad       0.71      0.63      0.67       360\n",
            "\n",
            "    accuracy                           0.56      1629\n",
            "   macro avg       0.57      0.55      0.56      1629\n",
            "weighted avg       0.57      0.56      0.56      1629\n",
            "\n",
            "Class Wise Accuracy\n",
            "\n",
            "ang  :  0.44385026737967914\n",
            "exc  :  0.5\n",
            "neu  :  0.6333938294010889\n",
            "sad  :  0.6277777777777778\n"
          ]
        }
      ]
    }
  ]
}